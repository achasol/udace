## UDACE

A Julia Implementation of the Utility & Distribution Aware Counterfactual Explanations (UDACE) method
For my undergraduate thesis in Econometrics & Economics at the Erasmus University Rotterdam.

### Background
UDACE is an extension on the Distribution Aware Counterfactual Explanation (DACE) method developed by Kanamori, Takagi, Kobayashi and Arimura (2020). I decided to use  Julia because it has a great library for solving MIP problems, so I took the [JuMP](https://jump.dev/) of faith ;), and decided to implement my UDACE method in Julia. 

To ensure feature parity with the DACE method, any implementation details not mentioned within the research paper were retrieved from the published [DACE source code](https://github.com/kelicht/dace). 
 
### Structure 
- The results used in my paper are contained in the results folder.
- The data used to estimate the models are in the data folder. 
- The synthetic preference data can also be found within the data folder. 
- All source code is contained within the src folder

### Usage
Make sure you have a working installation of [Julia](https://julialang.org/downloads/). The UDACE method
has been developed and tested on version 1.8.5. Proceed to clone or download this repo.
Open a terminal and navigate to the src folder within the project and execute: 
```
julia Setup.jl 
```
This script will install all required Julia dependencies. 

Once the dependencies are installed if you want to reproduce the results of my paper
then run 
```
julia UtilDace.jl 
```
Beware that producing all results can take quite some time, in particular for the FICO dataset. 

#### Is UDACE production ready?
No, this implementation of UDACE should be regarded as a proof of concept implementation. There are clear 
areas where the code needs to be improved. Hence I do not advise using this code for any use-case 
besides academic research. 

#### Note on exact reproduction of my results 
I forgot to fix the random_states of the LogisticRegression model,
this can cause the model to have parameters which are different eventhough
the exact same data is used. For more information see the scikit-learn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). 
Naturally this has an impact on the results generated by UDACE however given that I did
fix the random_state for the train_test_split, and the global seed, this should not be a cause for major differences. 

